{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, glob, re\n",
    "import threading\n",
    "import pypillometry as pp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "from scipy.interpolate import interp1d\n",
    "import math\n",
    "import bisect\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define functions to load in data\n",
    "def get_txt_files(directory):\n",
    "    os.chdir(directory)\n",
    "    txt_files = []\n",
    "    for file in glob.glob(\"*.txt\"):\n",
    "        txt_files.append(file)\n",
    "    return txt_files\n",
    "\n",
    "def load_pupil_data_from_disk(path_to_file):\n",
    "    data = []\n",
    "    with open(path_to_file, 'r') as file:\n",
    "        for current_line in file:\n",
    "            if current_line[:1] == '5':     # 5 in the first two letters means this is header\n",
    "                col_string = current_line\n",
    "                columnNames = col_string.strip().split('\\t')\n",
    "                if len(columnNames) == 18:\n",
    "                    columnNames.append('String')\n",
    "            elif current_line[:2] == '10':  # 10 in the first two letters means this is data\n",
    "                data_list = current_line.split('\\t')\n",
    "                # Remove any empty strings from the list\n",
    "                data_list = [i for i in data_list if i]\n",
    "                \n",
    "                if len(data_list[1:]) < 18:\n",
    "                    data_list.append([])\n",
    "                data.append(data_list[1:])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=columnNames[1:])\n",
    "    # replace new line marker to nans\n",
    "    df['Marker'] = df['Marker'].replace('\\n', np.nan)\n",
    "\n",
    "    # replace 'None' with nans\n",
    "    df = df.replace('None', np.nan)\n",
    "\n",
    "    # count occurences of Markers\n",
    "    df['Marker_Count'] = df.groupby('Marker').cumcount() + 1\n",
    "\n",
    "    ## add block and run information to df\n",
    "    block_start_list = df.loc[df['Marker'] == 'B'].index.tolist()\n",
    "    block_end_list = df.loc[df['Marker'] == 'E'].index.tolist()\n",
    "    run_start_list = df.loc[df['Marker'] == 'R'].index.tolist()\n",
    "    # create empty columns\n",
    "    df['Block'] = np.nan\n",
    "    df['Run'] = np.nan\n",
    "    # go through blocks\n",
    "    for idx,_ in enumerate(block_start_list):\n",
    "        try:\n",
    "            df.loc[block_start_list[idx]:block_end_list[idx], 'Block'] = df.loc[block_start_list[idx],'Marker_Count']\n",
    "        except:\n",
    "            endidx = df.index.to_list()\n",
    "            df.loc[block_start_list[idx]:endidx[-1], 'Block'] = df.loc[block_start_list[idx],'Marker_Count']\n",
    "    # go through runs\n",
    "\n",
    "    match = re.search('run(\\d+)', path_to_file)\n",
    "    if match:\n",
    "        number_run = match.group(1)\n",
    "\n",
    "    # df.loc[run_start_list[idx],'Marker_Count'].astype(int)\n",
    "\n",
    "    for idx,_ in enumerate(run_start_list):\n",
    "\n",
    "        if idx < len(run_start_list)-1:\n",
    "            # get end of last block in run\n",
    "            pos_end = bisect.bisect_right(block_end_list, run_start_list[idx+1])\n",
    "            closest_end = block_end_list[pos_end-1] if pos_end else None\n",
    "\n",
    "            df.loc[run_start_list[idx]:closest_end, 'Run'] = df.loc[run_start_list[idx],'Marker_Count'] + (int(number_run)-1)\n",
    "        else:\n",
    "            df.loc[run_start_list[idx]:block_end_list[-1], 'Run'] = df.loc[run_start_list[idx],'Marker_Count'] + (int(number_run)-1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_df_prepross(df, sub_name): # event_df_no_nans, \n",
    "\n",
    "    df['PupilHeight'] = df['PupilHeight'].astype(float)\n",
    "    df['PupilWidth'] = df['PupilWidth'].astype(float)\n",
    "    df['PupilArea'] = math.pi * (df['PupilWidth']/2) * (df['PupilHeight']/2)\n",
    "    \n",
    "    new_df = df[['TotalTime', 'PupilArea', 'Block', 'Run', 'Marker', 'Marker_Count']].copy()\n",
    "    new_df = new_df.rename(columns={'TotalTime': 'time', 'PupilArea': 'pupil'})\n",
    "\n",
    "    min_run = int(new_df['Run'].min())\n",
    "    max_run = int(new_df['Run'].max())\n",
    "\n",
    "    cur_run = min_run\n",
    "\n",
    "    print(sub_name,' ,runs ',min_run,' to ', max_run)\n",
    "\n",
    "    # run_data = {}\n",
    "    run_data = {run: None for run in range(min_run,max_run+1)}\n",
    "    count = 0\n",
    "    for cur_run in range(min_run,max_run+1):\n",
    "        \n",
    "        # skip skip runs in order to avoid issues with experimens with multiple files\n",
    "        if ((sub_name == 'S9') and (cur_run == 11) and(min_run == 1)) or ((sub_name == 'S22') and (cur_run == 4) and(min_run == 1)) or ((sub_name == 'S28') and (cur_run == 11) and(min_run == 2)):\n",
    "            continue\n",
    "\n",
    "        # select subset of data only containing current run (to avoid drifting pupil data)\n",
    "        # event_df_run = event_df_no_nans.loc[event_df_no_nans['Run'] == cur_run].copy()\n",
    "\n",
    "        # event_df_run = event_df_run.loc[event_df_run['event'] != 'O']\n",
    "\n",
    "        pp_data = new_df.copy()\n",
    "        pp_data = pp_data.loc[pp_data['Run'] == cur_run]\n",
    "\n",
    "        pp_data['time'] = pp_data['time'].astype(float) * 1000 # convert sec to ms\n",
    "\n",
    "        pp_data['time'] = pp_data['time'].astype(float)\n",
    "        samp = 1000/pp_data['time'].diff().mean()\n",
    "        # print(samp)\n",
    "\n",
    "        data_name = sub_name + '-' + str(cur_run)\n",
    "\n",
    "        pp_data.to_csv('/Users/scanlab/Documents/internship_luca/Pupil_data_Maastricht/pupilFieldtrip/blocks/'+data_name+'.csv') \n",
    "    return\n",
    "\n",
    "\n",
    "    ## define functions to load in data\n",
    "def get_csv_files(directory):\n",
    "    os.chdir(directory)\n",
    "    csv_files = []\n",
    "    for file in glob.glob(\"*.csv\"):\n",
    "        csv_files.append(file)\n",
    "    return csv_files\n",
    "\n",
    "def time_accurate_resampling(df, target_samp_freq, time_col_name='time'):\n",
    "    \n",
    "    # setup time data correctly\n",
    "    df['timestamp'] = pd.to_datetime(df[time_col_name], unit='ms')\n",
    "    df = df.set_index('timestamp') \n",
    "\n",
    "    # do resampling of time-data\n",
    "    time_window_sec = 1000/target_samp_freq\n",
    "    time_window = str(time_window_sec)+'ms' # create string for resampling function\n",
    "\n",
    "    # df['Marker_int'] = df['Marker'].apply(lambda x: 0 if pd.isna(x) else ord(x) if isinstance(x, str) and len(x) == 1 else 0)\n",
    "    resampled_df = df.resample(time_window).mean(numeric_only=True) # takes out marker column\n",
    "\n",
    "    ## perform resampling of pupil data\n",
    "    # - seconds from start:\n",
    "    time_seconds = (df.index - df.index[0]).total_seconds()\n",
    "    # - interpolation function:\n",
    "    f = interp1d(time_seconds, df['pupil'], kind='cubic', fill_value='extrapolate') \n",
    "    # - new timestamps based on resampled index:\n",
    "    new_time_seconds = (resampled_df.index - resampled_df.index[0]).total_seconds()\n",
    "    # - interpolate the data:\n",
    "    resampled_df['pupil_resampled'] = f(new_time_seconds)\n",
    "\n",
    "    # put marker back into data\n",
    "    # resampled_df = pd.concat([resampled_df, df.loc[df['Marker'].notna()]], axis=1)\n",
    "    for t in df.loc[df['Marker'] == 'B'].index:\n",
    "        time_diff = np.abs(resampled_df.index - t)\n",
    "        resampled_df.loc[resampled_df.index[np.argmin(time_diff)],'Marker'] = 'B'\n",
    "\n",
    "    for t in df.loc[df['Marker'] == 'E'].index:\n",
    "        time_diff = np.abs(resampled_df.index - t)\n",
    "        resampled_df.loc[resampled_df.index[np.argmin(time_diff)],'Marker'] = 'E'\n",
    "    \n",
    "\n",
    "    resampled_df['time_new'] = resampled_df.index\n",
    "    resampled_df['time_new'] = resampled_df['time_new'].astype(np.int64) / int(1e6)\n",
    "\n",
    "    # interpolate missing pupil data\n",
    "    resampled_df['pupil'] = resampled_df['pupil'].interpolate()\n",
    "\n",
    "    return resampled_df\n",
    "\n",
    "    def remove(string, i): \n",
    "        if i > len(string): \n",
    "            return string \n",
    "        a = list(string) \n",
    "        a.pop(i) \n",
    "        return \"\".join(a) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create csv from pupil-data txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S10  ,runs  1  to  16\n",
      "S11  ,runs  1  to  16\n",
      "S12  ,runs  1  to  16\n",
      "S13  ,runs  1  to  11\n",
      "S13  ,runs  11  to  16\n",
      "S14  ,runs  1  to  16\n",
      "S15  ,runs  1  to  16\n",
      "S16  ,runs  1  to  16\n",
      "S17  ,runs  1  to  16\n",
      "S18  ,runs  1  to  3\n",
      "S18  ,runs  4  to  16\n",
      "S19  ,runs  1  to  16\n",
      "S1  ,runs  4  to  16\n",
      "S1  ,runs  1  to  3\n",
      "S20  ,runs  1  to  16\n",
      "S21  ,runs  1  to  16\n",
      "S22  ,runs  4  to  16\n",
      "S22  ,runs  1  to  4\n",
      "S23  ,runs  1  to  16\n",
      "S24  ,runs  1  to  16\n",
      "S25  ,runs  1  to  16\n",
      "S26  ,runs  1  to  16\n",
      "S27  ,runs  1  to  16\n",
      "S28  ,runs  11  to  16\n",
      "S28  ,runs  1  to  1\n",
      "S28  ,runs  2  to  10\n",
      "S2  ,runs  1  to  16\n",
      "S3  ,runs  1  to  16\n",
      "S4  ,runs  1  to  16\n",
      "S5  ,runs  1  to  16\n",
      "S6  ,runs  1  to  16\n",
      "S7  ,runs  1  to  16\n",
      "S8  ,runs  1  to  16\n",
      "S9  ,runs  11  to  16\n",
      "S9  ,runs  1  to  11\n"
     ]
    }
   ],
   "source": [
    "# load available files\n",
    "rel_dir = \"/Users/scanlab/Documents/internship_luca/Pupil_data_Maastricht/testing/eyetracking_data/\"\n",
    "file_names = get_txt_files(rel_dir)\n",
    "file_names.sort(key=lambda x: x[0:2])\n",
    "\n",
    "# go through each file and create csv\n",
    "for file in file_names:\n",
    "\n",
    "    if file[1] == '_':\n",
    "        sub_name = 'S'+str(file[0])  # get sub name/number\n",
    "    else:\n",
    "        sub_name = 'S'+str(file[:2]) # get sub name/number\n",
    "\n",
    "    df = load_pupil_data_from_disk(rel_dir+file)\n",
    "\n",
    "    create_df_prepross(df, sub_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# time-accurate downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob_dir = \"/Users/scanlab/Documents/internship_luca/Pupil_data_Maastricht/pupilFieldtrip/blocks/\"\n",
    "\n",
    "file_names = get_csv_files(glob_dir)\n",
    "file_names.sort(key=lambda x: x)\n",
    "\n",
    "target_hz = 125\n",
    "\n",
    "# perform downsampling\n",
    "for file in file_names:\n",
    "    df = pd.read_csv(glob_dir+file) \n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "    resampled_df = time_accurate_resampling(df, target_hz, 'time')\n",
    "\n",
    "    resampled_df.to_csv(glob_dir+'predown/'+file[:-4]+'.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
